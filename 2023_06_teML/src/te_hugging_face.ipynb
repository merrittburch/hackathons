{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a76c0d-1156-49a1-be94-651856f9efa1",
   "metadata": {},
   "source": [
    "##### Author: Merritt Khaipho-Burch\n",
    "##### Contact: mbb262@cornell.edu\n",
    "##### Date: 2023-06-05\n",
    "##### Updated: 2023-06-07\n",
    "\n",
    "##### Description:\n",
    "- Set up nucleotide transformer model from hugging face\n",
    "- load formatted TE data\n",
    "- run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304449ae-7a92-40f1-8c7b-0e58d45af4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as npa\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b35cf5-54fa-4876-98a0-713c94aa0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-2.5b-multi-species\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18223e2f-9deb-4e78-b659-70f5bb8c2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data ['gene', 'avg_fpkm', 'class', 'upSeq', 'upSeq2k']\n",
    "trainSeq = pd.read_csv(filepath_or_buffer='/workdir/mbb262/te/te_sequence_with_walley_expression.txt', delimiter='\\t')\n",
    "trainSeq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32e9af-b8aa-44f2-83d7-1ee03fcdf50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at top of dataset\n",
    "trainSeq.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13570f5d-c274-49d3-a002-8b80ff8e8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input sequences\n",
    "inputSeq = trainSeq['teSeq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e757f-71f8-4d52-9fad-5a6504b1a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model\n",
    "resEmbeddings = np.empty((0, 2560))\n",
    "for i in range(0, len(inputSeq), 30):\n",
    "    tokens_ids = tokenizer.batch_encode_plus(inputSeq[i:i+10], return_tensors=\"pt\", \n",
    "                                             padding=True, truncation=True)[\"input_ids\"]\n",
    "    tokens_ids = tokens_ids.to(device)\n",
    "    attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "    with torch.no_grad():\n",
    "        torch_outs = model(\n",
    "        tokens_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        encoder_attention_mask=attention_mask,\n",
    "        output_hidden_states=True)\n",
    "    embeddings = torch_outs['hidden_states'][-1].detach().cpu().numpy()\n",
    "    attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "    attention_mask = attention_mask.cpu().numpy()\n",
    "    attention_mask = np.expand_dims(attention_mask, axis = -1)\n",
    "    masked_embeddings = embeddings * attention_mask  # multiply by 0 pad tokens embeddings\n",
    "    sequences_lengths = np.sum(attention_mask, axis=1)\n",
    "    mean_embeddings = np.sum(masked_embeddings, axis=1) / sequences_lengths\n",
    "    resEmbeddings = np.append(resEmbeddings, mean_embeddings, axis=0)\n",
    "    # print progress bar\n",
    "    print(f\"{i+1}/{len(inputSeq)}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f565bf-9c65-4338-aba1-6199f880b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "np.savetxt(fname = '/workdir/mbb262/Pg_X_test.txt', X=resEmbeddings, delimiter='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging-face",
   "language": "python",
   "name": "hugging-face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
